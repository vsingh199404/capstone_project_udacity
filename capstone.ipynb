{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nSEED=2\nimport os\n\ntrain=pd.read_csv(\"/kaggle/input/aptos2019-blindness-detection/train.csv\")\nsubmition=pd.read_csv(\"/kaggle/input/aptos2019-blindness-detection/test.csv\")\n\nx = train['id_code']\ny = train['diagnosis']\n\nx,y=shuffle(x,y)\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_X,X_test,df_y,y_test=train_test_split(x, y, test_size=0.15)\n\nX_train,X_valid,y_train,y_valid=train_test_split(df_X, df_y, test_size=0.15)\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_ben_color(path, sigmaX=20):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image1(img,tol=7):\n    # img is image data\n    # tol  is tolerance\n        \n    mask = img>tol\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport cv2\ntrain_images=[]\nIMG_SIZE=224\n%time\nfig = plt.figure(figsize=(25, 16))\n\nfor idx, row in enumerate(X_train):\n    \n    path=f\"../input/aptos2019-blindness-detection/train_images/{row}.png\"\n    image =load_ben_color(path)\n    train_images.append(image)\n\n        ","execution_count":5,"outputs":[{"output_type":"stream","text":"CPU times: user 0 ns, sys: 0 ns, total: 0 ns\nWall time: 8.58 µs\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1800x1152 with 0 Axes>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport cv2\ntest_images=[]\nIMG_SIZE=224\n%time\nfig = plt.figure(figsize=(25, 16))\n\nfor idx, row in enumerate(X_test):\n    \n    path=f\"../input/aptos2019-blindness-detection/train_images/{row}.png\"\n    image =load_ben_color(path)\n    test_images.append(image)\n","execution_count":6,"outputs":[{"output_type":"stream","text":"CPU times: user 0 ns, sys: 0 ns, total: 0 ns\nWall time: 8.11 µs\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1800x1152 with 0 Axes>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport cv2\nvalid_images=[]\nIMG_SIZE=224\n%time\nfig = plt.figure(figsize=(25, 16))\n\nfor idx, row in enumerate(X_valid):\n    \n    path=f\"../input/aptos2019-blindness-detection/train_images/{row}.png\"\n    image =load_ben_color(path)\n    valid_images.append(image)","execution_count":7,"outputs":[{"output_type":"stream","text":"CPU times: user 0 ns, sys: 0 ns, total: 0 ns\nWall time: 8.34 µs\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1800x1152 with 0 Axes>"},"metadata":{}}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, load_model\nfrom keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D)\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import metrics\nfrom keras.optimizers import Adam \nfrom keras import backend as K\nimport keras\nfrom keras.models import Model\nNUM_CLASSES=5","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\ny_train_dummies=to_categorical(y_train,num_classes=NUM_CLASSES)\ny_test_dummies=to_categorical(y_test,num_classes=NUM_CLASSES)\ny_valid_dummies=to_categorical(y_valid,num_classes=NUM_CLASSES)\ny_train_dummies","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"array([[1., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       ...,\n       [0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0.]], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport time\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.layers import Dense, Activation, Flatten\nfrom keras.layers import merge, Input\nfrom keras.models import Model\nfrom keras.utils import np_utils\nimport os\n\n\n","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_Classes=5\n\ntrain=np.array(train_images)\ntest=np.array(test_images)\nvalid=np.array(valid_images)\n\nnum_of_samples=train.shape[0]\ntrain.shape","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"(2645, 224, 224, 3)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\n# create and configure augmented image generator\ndatagen_train = ImageDataGenerator(\n    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n    horizontal_flip=True) # randomly flip images horizontally\n\n# create and configure augmented image generator\ndatagen_valid = ImageDataGenerator(\n    width_shift_range=0.1,  # randomly shift images horizontally (10% of total width)\n    height_shift_range=0.1,  # randomly shift images vertically (10% of total height)\n    horizontal_flip=True) # randomly flip images horizontally\n\n# fit augmented image generator on data\ndatagen_train.fit(train)\ndatagen_valid.fit(valid)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\n\n# take subset of training data\nx_train_subset = train[:12]\nfig = plt.figure(figsize=(20,2))\nfor x_batch in datagen_train.flow(x_train_subset, batch_size=12):\n    for i in range(0, 12):\n        ax = fig.add_subplot(1, 12, i+1)\n        ax.imshow(x_batch[i])\n    fig.suptitle('Augmented Images', fontsize=20)\n    plt.show()\n    break;","execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1440x144 with 12 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image                  \nimage_input=Input(shape=train.shape[1:])\nmodel=VGG16(input_tensor=image_input, weights='imagenet')\nmodel.summary()","execution_count":14,"outputs":[{"output_type":"stream","text":"Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n553467904/553467096 [==============================] - 12s 0us/step\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 224, 224, 3)       0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 4096)              102764544 \n_________________________________________________________________\nfc2 (Dense)                  (None, 4096)              16781312  \n_________________________________________________________________\npredictions (Dense)          (None, 1000)              4097000   \n=================================================================\nTotal params: 138,357,544\nTrainable params: 138,357,544\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nlast_layer=model.get_layer('fc1').output\nlast_layer=Dropout(0.2)(last_layer)\n\nlast_layer=Dense(1024)(last_layer)\nlast_layer=BatchNormalization()(last_layer)\nlast_layer=Activation('relu')(last_layer)\nlast_layer=last_layer=Dropout(0.2)(last_layer)\nlast_layer=Dense(512, activation='relu')(last_layer)\nlast_layer=BatchNormalization()(last_layer)\nlast_layer=Activation('relu')(last_layer)\nlast_layer=Dropout(0.2)(last_layer)\n\nout=Dense(num_Classes,activation='softmax', name='output')(last_layer)\n\ncustom_vgg_model=Model(image_input,out)\ncustom_vgg_model.summary()","execution_count":15,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 224, 224, 3)       0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\nfc1 (Dense)                  (None, 4096)              102764544 \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 4096)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1024)              4195328   \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 1024)              4096      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 1024)              0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 1024)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               524800    \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 512)               2048      \n_________________________________________________________________\nactivation_2 (Activation)    (None, 512)               0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 512)               0         \n_________________________________________________________________\noutput (Dense)               (None, 5)                 2565      \n=================================================================\nTotal params: 122,208,069\nTrainable params: 122,204,997\nNon-trainable params: 3,072\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in custom_vgg_model.layers[:-10]:\n    layer.trainable=False","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"custom_vgg_model.compile(loss=\"categorical_crossentropy\", optimizer='Adam',  metrics=['accuracy'])\n","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=32\nt=time.time()\n\ncustom_vgg_model.fit_generator(datagen_train.flow(train, y_train_dummies, batch_size=batch_size),\n                    steps_per_epoch=train.shape[0]/32,\n                    epochs=2, verbose=2,\n                    validation_data=datagen_valid.flow(valid, y_valid_dummies, batch_size=batch_size),validation_steps=valid.shape[0]/32)\nprint(\"training time: %s\" %(t-time.time()))","execution_count":19,"outputs":[{"output_type":"stream","text":"Epoch 1/2\n - 32s - loss: 0.9921 - acc: 0.6602 - val_loss: 1.0522 - val_acc: 0.6809\nEpoch 2/2\n - 27s - loss: 0.7659 - acc: 0.7243 - val_loss: 0.6727 - val_acc: 0.7623\ntraining time: -60.69081521034241\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nepochs = 100\n\n\nt=time.time()\n\ncustom_vgg_model.fit_generator(datagen_train.flow(train, y_train_dummies, batch_size=batch_size),\n                    steps_per_epoch=train.shape[0]/16,\n                    epochs=40, verbose=2,\n                    validation_data=datagen_valid.flow(valid, y_valid_dummies, batch_size=batch_size),validation_steps=valid.shape[0]/16)\nprint(\"training time: %s\" %(t-time.time()))","execution_count":20,"outputs":[{"output_type":"stream","text":"Epoch 1/40\n - 59s - loss: 0.6788 - acc: 0.7498 - val_loss: 0.6326 - val_acc: 0.7784\nEpoch 2/40\n - 56s - loss: 0.6017 - acc: 0.7676 - val_loss: 0.6006 - val_acc: 0.7741\nEpoch 3/40\n - 56s - loss: 0.5834 - acc: 0.7820 - val_loss: 0.6718 - val_acc: 0.7505\nEpoch 4/40\n - 56s - loss: 0.5427 - acc: 0.7906 - val_loss: 0.5725 - val_acc: 0.8019\nEpoch 5/40\n - 55s - loss: 0.5283 - acc: 0.8012 - val_loss: 0.5746 - val_acc: 0.7901\nEpoch 6/40\n - 56s - loss: 0.5053 - acc: 0.8124 - val_loss: 0.5944 - val_acc: 0.7966\nEpoch 7/40\n - 56s - loss: 0.4789 - acc: 0.8173 - val_loss: 0.6165 - val_acc: 0.7827\nEpoch 8/40\n - 56s - loss: 0.4801 - acc: 0.8194 - val_loss: 0.5609 - val_acc: 0.8019\nEpoch 9/40\n - 56s - loss: 0.4646 - acc: 0.8194 - val_loss: 0.6296 - val_acc: 0.7891\nEpoch 10/40\n - 56s - loss: 0.4380 - acc: 0.8370 - val_loss: 0.5896 - val_acc: 0.7773\nEpoch 11/40\n - 56s - loss: 0.4318 - acc: 0.8394 - val_loss: 0.5939 - val_acc: 0.7934\nEpoch 12/40\n - 56s - loss: 0.4287 - acc: 0.8303 - val_loss: 0.6293 - val_acc: 0.7805\nEpoch 13/40\n - 56s - loss: 0.4194 - acc: 0.8371 - val_loss: 0.6248 - val_acc: 0.7912\nEpoch 14/40\n - 56s - loss: 0.4129 - acc: 0.8417 - val_loss: 0.6510 - val_acc: 0.7859\nEpoch 15/40\n - 56s - loss: 0.3991 - acc: 0.8467 - val_loss: 0.6589 - val_acc: 0.7880\nEpoch 16/40\n - 56s - loss: 0.3866 - acc: 0.8479 - val_loss: 0.6461 - val_acc: 0.7934\nEpoch 17/40\n - 56s - loss: 0.3867 - acc: 0.8593 - val_loss: 0.6404 - val_acc: 0.7923\nEpoch 18/40\n - 56s - loss: 0.3642 - acc: 0.8610 - val_loss: 0.6220 - val_acc: 0.7966\nEpoch 19/40\n - 56s - loss: 0.3530 - acc: 0.8661 - val_loss: 0.6664 - val_acc: 0.7923\nEpoch 20/40\n - 56s - loss: 0.3448 - acc: 0.8691 - val_loss: 0.6986 - val_acc: 0.7730\nEpoch 21/40\n - 56s - loss: 0.3597 - acc: 0.8623 - val_loss: 0.6733 - val_acc: 0.8094\nEpoch 22/40\n - 56s - loss: 0.3349 - acc: 0.8734 - val_loss: 0.6509 - val_acc: 0.7923\nEpoch 23/40\n - 58s - loss: 0.3369 - acc: 0.8766 - val_loss: 0.6425 - val_acc: 0.8084\nEpoch 24/40\n - 57s - loss: 0.3119 - acc: 0.8818 - val_loss: 0.6738 - val_acc: 0.7987\nEpoch 25/40\n - 57s - loss: 0.3222 - acc: 0.8727 - val_loss: 0.7153 - val_acc: 0.8051\nEpoch 26/40\n - 57s - loss: 0.3244 - acc: 0.8724 - val_loss: 0.7232 - val_acc: 0.7784\nEpoch 27/40\n - 57s - loss: 0.2982 - acc: 0.8881 - val_loss: 0.6813 - val_acc: 0.7912\nEpoch 28/40\n - 57s - loss: 0.3054 - acc: 0.8873 - val_loss: 0.6542 - val_acc: 0.8009\nEpoch 29/40\n - 57s - loss: 0.3026 - acc: 0.8838 - val_loss: 0.6881 - val_acc: 0.7934\nEpoch 30/40\n - 57s - loss: 0.2859 - acc: 0.8915 - val_loss: 0.6978 - val_acc: 0.7805\nEpoch 31/40\n - 57s - loss: 0.2853 - acc: 0.8899 - val_loss: 0.6898 - val_acc: 0.8094\nEpoch 32/40\n - 57s - loss: 0.2721 - acc: 0.8980 - val_loss: 0.6947 - val_acc: 0.8116\nEpoch 33/40\n - 57s - loss: 0.2619 - acc: 0.9026 - val_loss: 0.7765 - val_acc: 0.7805\nEpoch 34/40\n - 57s - loss: 0.2730 - acc: 0.8986 - val_loss: 0.7208 - val_acc: 0.7880\nEpoch 35/40\n - 57s - loss: 0.2455 - acc: 0.8987 - val_loss: 0.7634 - val_acc: 0.7880\nEpoch 36/40\n - 57s - loss: 0.2472 - acc: 0.9054 - val_loss: 0.7945 - val_acc: 0.7816\nEpoch 37/40\n - 57s - loss: 0.2572 - acc: 0.9004 - val_loss: 0.7347 - val_acc: 0.7966\nEpoch 38/40\n - 56s - loss: 0.2514 - acc: 0.9086 - val_loss: 0.7599 - val_acc: 0.7880\nEpoch 39/40\n - 57s - loss: 0.2509 - acc: 0.9051 - val_loss: 0.7873 - val_acc: 0.8009\nEpoch 40/40\n - 57s - loss: 0.2636 - acc: 0.9023 - val_loss: 0.7517 - val_acc: 0.8126\ntraining time: -2257.5189917087555\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"(loss, accuracy)=custom_vgg_model.evaluate(test,y_test_dummies,verbose=1 ,batch_size=32)\nprint(loss)\nprint(accuracy*100)","execution_count":21,"outputs":[{"output_type":"stream","text":"550/550 [==============================] - 2s 3ms/step\n0.8126240663094954\n78.54545456712896\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\npredicted=[]\nsubmit = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\nfor i, name in tqdm(enumerate(submit['id_code'])):\n    path = os.path.join('../input/aptos2019-blindness-detection/test_images/', name+'.png')\n    \n    image = load_ben_color(path)\n    image = cv2.resize(image, (224, 224))\n    score_predict = model.predict((image[np.newaxis])/255)\n    label_predict = np.argmax(score_predict)\n    #label_predict = score_predict.astype(int).sum() - 1\n    predicted.append(str(label_predict))","execution_count":22,"outputs":[{"output_type":"stream","text":"1928it [02:55, 11.00it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit['diagnosis'] = predicted\nsubmit.to_csv('submission.csv', index=False)\nsubmit.head()","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"        id_code diagnosis\n0  0005cfc8afb6       669\n1  003f0afdcd15       669\n2  006efc72b638       669\n3  00836aaacf06       669\n4  009245722fa4       669","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_code</th>\n      <th>diagnosis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0005cfc8afb6</td>\n      <td>669</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>003f0afdcd15</td>\n      <td>669</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>006efc72b638</td>\n      <td>669</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>00836aaacf06</td>\n      <td>669</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>009245722fa4</td>\n      <td>669</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}