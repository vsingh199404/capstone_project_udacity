{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n",
    "                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D,MaxPooling2D)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import metrics\n",
    "from keras.optimizers import Adam \n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import merge, Input\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "SEED=2\n",
    "\n",
    "train=pd.read_csv(\"inputs/train.csv\")\n",
    "submition=pd.read_csv(\"inputs/test.csv\")\n",
    "\n",
    "x = train['id_code']\n",
    "y = train['diagnosis']\n",
    "\n",
    "x,y=shuffle(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X,X_test,df_y,y_test=train_test_split(x, y, test_size=0.15)\n",
    "\n",
    "X_train,X_valid,y_train,y_valid=train_test_split(df_X, df_y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def load_ben_color(path, sigmaX=20):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = crop_image_from_gray(image)\n",
    "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image1(img,tol=7):\n",
    "    # img is image data\n",
    "    # tol  is tolerance\n",
    "        \n",
    "    mask = img>tol\n",
    "    return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "\n",
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "    #         print(img1.shape,img2.shape,img3.shape)\n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "    #         print(img.shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "test_images=[]\n",
    "IMG_SIZE=300\n",
    "%time\n",
    "fig = plt.figure(figsize=(25, 16))\n",
    "\n",
    "for idx, row in enumerate(X_test):\n",
    "    \n",
    "    path=f\"inputs/train_images/{row}.png\"\n",
    "    \n",
    "    image =load_ben_color(path)\n",
    "    test_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_images=[]\n",
    "%time\n",
    "fig = plt.figure(figsize=(25, 16))\n",
    "\n",
    "for idx, row in enumerate(X_test):\n",
    "    \n",
    "    path=f\"inputs/train_images/{row}.png\"\n",
    "    image =load_ben_color(path)\n",
    "    train_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_images=[]\n",
    "\n",
    "%time\n",
    "fig = plt.figure(figsize=(25, 16))\n",
    "\n",
    "for idx, row in enumerate(X_test):\n",
    "    \n",
    "    path=f\"inputs/train_images/{row}.png\"\n",
    "    image =load_ben_color(path)\n",
    "    valid_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the ResNet50 model\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "#Loading the ResNet50 model with pre-trained ImageNet weights\n",
    "model = ResNet50(weights='imagenet', include_top=False, input_shape=(300, 300, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping the testing data\n",
    "test=np.array(test_images)\n",
    "\n",
    "#Preprocessing the data, so that it can be fed to the pre-trained ResNet50 model.\n",
    "resnet_test_input = preprocess_input(test)\n",
    "\n",
    "#Creating bottleneck features for the testing data\n",
    "test_features = model.predict(resnet_test_input)\n",
    "\n",
    "#Saving the bottleneck features\n",
    "np.savez('bottleneck/resnet_features_test', features=test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping the testing data\n",
    "train=np.array(train_images)\n",
    "\n",
    "#Preprocessing the data, so that it can be fed to the pre-trained ResNet50 model.\n",
    "resnet_train_input = preprocess_input(train)\n",
    "\n",
    "#Creating bottleneck features for the testing data\n",
    "train_features = model.predict(resnet_train_input)\n",
    "\n",
    "#Saving the bottleneck features\n",
    "np.savez('bottleneck/resnet_features_train', features=train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping the testing data\n",
    "valid=np.array(valid_images)\n",
    "\n",
    "#Preprocessing the data, so that it can be fed to the pre-trained ResNet50 model.\n",
    "resnet_valid_input = preprocess_input(valid)\n",
    "\n",
    "#Creating bottleneck features for the testing data\n",
    "valid_features = model.predict(resnet_valid_input)\n",
    "\n",
    "#Saving the bottleneck features\n",
    "np.savez('bottleneck/resnet_features_valid', features=valid_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
